\subsection{Decomposition of task}
First challenge is to decompose a task into smaller sub-tasks, which then can be executed by a subset of skills. Or in other words, given a set of skills, how to select a subset of skills to execute a task during inference. This is a well studied problem in the field of Hierarchical Reinforcement Learning (HRL) \cite{hutsebaut-buysseHierarchicalReinforcementLearning2022} .

\subsection{Subtask discovery}
Next challenge is to identify which skills to learn during training. This is usually done by

\begin{itemize}
\item \textbf{Bottom-up approach:} 
Handpicking a set of primitive skills, intuitively, and training them individually. Later, they are frozen and put together for training the high-level policy. This method is widely used. \cite{pateriaHierarchicalReinforcementLearning2021}.
\end{itemize}

However, this approach can not be generalized. And also handcrafting the set of skills is not optimal \cite{silverWelcomeEraExperience}.

\begin{itemize}
\item \textbf{Top-down approach:}
Train both high-level and low-level policies together. And number of low-level policies or skills is not fixed. This introduces a new hurdle: non stationary transistion function for the high-level policy.

\end{itemize}
% non stationary transition function - feudal 
% subtask disco - model
% training time