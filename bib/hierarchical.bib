@article{alattasEvolutionaryModularRobotics2019,
  title = {Evolutionary {{Modular Robotics}}: {{Survey}} and {{Analysis}}},
  shorttitle = {Evolutionary {{Modular Robotics}}},
  author = {Alattas, Reem J. and Patel, Sarosh and Sobh, Tarek M.},
  year = {2019},
  month = sep,
  journal = {Journal of Intelligent \& Robotic Systems},
  volume = {95},
  number = {3},
  pages = {815--828},
  issn = {1573-0409},
  doi = {10.1007/s10846-018-0902-9},
  urldate = {2025-05-23},
  abstract = {This paper surveys various applications of artificial evolution in the field of modular robots. Evolutionary robotics aims to design autonomous adaptive robots automatically that can evolve to accomplish a specific task while adapting to environmental changes. A number of studies have demonstrated the feasibility of evolutionary algorithms for generating robotic control and morphology. However, a huge challenge faced was how to manufacture these robots. Therefore, modular robots were employed to simplify robotic evolution and their implementation in real hardware. Consequently, more research work has emerged on using evolutionary computation to design modular robots rather than using traditional hand design approaches in order to avoid cognition bias. These techniques have the potential of developing adaptive robots that can achieve tasks not fully understood by human designers. Furthermore, evolutionary algorithms were studied to generate global modular robotic behaviors including; self-assembly, self-reconfiguration, self-repair, and self-reproduction. These characteristics allow modular robots to explore unstructured and hazardous environments. In order to accomplish the aforementioned evolutionary modular robotic promises, this paper reviews current research on evolutionary robotics and modular robots. The motivation behind this work is to identify the most promising methods that can lead to developing autonomous adaptive robotic systems that require the minimum task related knowledge on the designer side.},
  langid = {english},
  keywords = {Bioinspired Robotics,Evolutionary robotics,Evolvability,Modular robots,Rehabilitation Robotics,Robotic Engineering,Robotics,Self-assembly,Self-reconfiguration,Self-repair,Self-reproduction,Social Robotics,Task-based design},
  file = {/home/vaishnavahari/Zotero/storage/ZMIKTV9D/Alattas et al. - 2019 - Evolutionary Modular Robotics Survey and Analysis.pdf}
}

@article{baconOptionCriticArchitecture2017,
  title = {The {{Option-Critic Architecture}}},
  author = {Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  year = {2017},
  month = feb,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {31},
  number = {1},
  issn = {2374-3468},
  doi = {10.1609/aaai.v31i1.10916},
  urldate = {2025-05-07},
  abstract = {Temporal abstraction is key to scaling up learning and planning in reinforcement learning. While planning with temporally extended actions is well understood, creating such abstractions autonomously from data has remained challenging.We tackle this problem in the framework of options [Sutton,Precup and Singh, 1999; Precup, 2000]. We derive policy gradient theorems for options and propose a new option-critic architecture capable of learning both the internal policies and the termination conditions of options, in tandem with the policy over options, and without the need to provide any additional rewards or subgoals. Experimental results in both discrete and continuous environments showcase the flexibility and efficiency of the framework.},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/DAS5LHKH/Bacon et al. - 2017 - The Option-Critic Architecture.pdf}
}

@phdthesis{beaussantTransferLearningRobots2023,
  title = {Transfer Learning between Robots with State Abstraction},
  author = {Beaussant, Samuel},
  year = {2023},
  month = sep,
  urldate = {2025-05-26},
  abstract = {Despite numerous improvements regarding the effectiveness of ac\{rl\} methods in robotics, training from scratch still requires millions (or even tens of millions) of interactions with the environment to converge on high-performance behavior. In order to alleviate this huge need for data without losing performance, one promising avenue is ac\{tl\}. The aim of this thesis is to explore transfer learning in the context of RL, with the specific aim of transferring behaviors from one robot to another, even in the presence of morphological divergences or different state-action spaces. In particular, this thesis presents a process for reusing past knowledge acquired by a robot (source) on a task to accelerate (or even avoid) the learning process of a different robot (target) on the same task. The proposed method relies first on an unsupervised pre-training phase to learn a robot-agnostic latent space from trajectories collected on a set of robots. Then, it is possible to train a model within this space to solve a given task, in order to produce a task module that can be reused by any robot sharing this common feature space. In addition, this thesis tackles the problem of simulation-to-real-world adaptation when transferring a model trained in a simulator, with a focus on delay management, which is often overlook in the current literature. Indeed, we show that models oblivious to delay significantly drop in performance when tested on a physical robot, where the hardware and sensory system inevitably introduce delay. The approach developed is a simple but effective one for training agents to handle a user-defined range of delays. Through several robotic tasks and heterogeneous hardware platforms, both in simulation and on physical robots, this thesis shows the benefits of these approaches in terms of improved learning efficiency and performance. More specifically, we report zero-shot generalization in some instances, where performance after transfer is preserved. In the worst case, performance is recovered after a short adaptation on the target robot for a fraction of the training cost required to learn a policy with similar performance from scratch.},
  langid = {english},
  school = {Universit{\'e} Clermont Auvergne},
  file = {/home/vaishnavahari/Zotero/storage/N33BESSV/Beaussant - 2023 - Transfer learning between robots with state abstraction.pdf}
}

@article{bohlingerLearningRobotLocomotion,
  title = {Learning {{Robot Locomotion}} for {{Multiple Embodiments}}},
  author = {Bohlinger, Nico and Czechmanowski, Grzegorz and Krupka, Maciej and Kicki, Piotr and Walas, Krzysztof and Peters, Jan and Tateo, Davide},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/REA5X7D4/Bohlinger et al. - Learning Robot Locomotion for Multiple Embodiments.pdf}
}

@article{bongardEvolutionaryRobotics2013,
  title = {Evolutionary Robotics},
  author = {Bongard, Josh C.},
  year = {2013},
  month = aug,
  journal = {Commun. ACM},
  volume = {56},
  number = {8},
  pages = {74--83},
  issn = {0001-0782},
  doi = {10.1145/2493883},
  urldate = {2025-06-11},
  abstract = {Taking a biologically inspired approach to the design of autonomous, adaptive machines.},
  file = {/home/vaishnavahari/Zotero/storage/VAD44826/Bongard - 2013 - Evolutionary robotics.pdf}
}

@article{bongardMorphologicalChangeMachines2011,
  title = {Morphological Change in Machines Accelerates the Evolution of Robust Behavior},
  author = {Bongard, Josh},
  year = {2011},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {4},
  pages = {1234--1239},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1015390108},
  urldate = {2025-06-11},
  abstract = {Most animals exhibit significant neurological and morphological change throughout their lifetime. No robots to date, however, grow new morphological structure while behaving. This is due to technological limitations but also because it is unclear that morphological change provides a benefit to the acquisition of robust behavior in machines. Here I show that in evolving populations of simulated robots, if robots grow from anguilliform into legged robots during their lifetime in the early stages of evolution, and the anguilliform body plan is gradually lost during later stages of evolution, gaits are evolved for the final, legged form of the robot more rapidly---and the evolved gaits are more robust---compared to evolving populations of legged robots that do not transition through the anguilliform body plan. This suggests that morphological change, as well as the evolution of development, are two important processes that improve the automatic generation of robust behaviors for machines. It also provides an experimental platform for investigating the relationship between the evolution of development and robust behavior in biological organisms.},
  file = {/home/vaishnavahari/Zotero/storage/SZA2F9JP/Bongard - 2011 - Morphological change in machines accelerates the evolution of robust behavior.pdf}
}

@article{caoKnowledgeGraphEmbedding2024,
  title = {Knowledge {{Graph Embedding}}: {{A Survey}} from the {{Perspective}} of {{Representation Spaces}}},
  shorttitle = {Knowledge {{Graph Embedding}}},
  author = {Cao, Jiahang and Fang, Jinyuan and Meng, Zaiqiao and Liang, Shangsong},
  year = {2024},
  month = mar,
  journal = {ACM Comput. Surv.},
  volume = {56},
  number = {6},
  pages = {159:1--159:42},
  issn = {0360-0300},
  doi = {10.1145/3643806},
  urldate = {2025-05-26},
  abstract = {Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.},
  file = {/home/vaishnavahari/Zotero/storage/BSPJ32T7/Cao et al. - 2024 - Knowledge Graph Embedding A Survey from the Perspective of Representation Spaces.pdf}
}

@article{caoKnowledgeGraphEmbedding2024a,
  title = {Knowledge {{Graph Embedding}}: {{A Survey}} from the {{Perspective}} of {{Representation Spaces}}},
  shorttitle = {Knowledge {{Graph Embedding}}},
  author = {Cao, Jiahang and Fang, Jinyuan and Meng, Zaiqiao and Liang, Shangsong},
  year = {2024},
  month = mar,
  journal = {ACM Comput. Surv.},
  volume = {56},
  number = {6},
  pages = {159:1--159:42},
  issn = {0360-0300},
  doi = {10.1145/3643806},
  urldate = {2025-06-12},
  abstract = {Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.},
  file = {/home/vaishnavahari/Zotero/storage/L6IETZTR/Cao et al. - 2024 - Knowledge Graph Embedding A Survey from the Perspective of Representation Spaces.pdf}
}

@article{chewKinematicStructuralSynthesis1995,
  title = {Kinematic {{Structural Synthesis}} of {{Mechanisms Using Knowledge-Based Systems}}},
  author = {Chew, M. and Shen, S. N. T. and Issa, G. F.},
  year = {1995},
  month = mar,
  journal = {Journal of Mechanical Design},
  volume = {117},
  number = {1},
  pages = {96--103},
  publisher = {ASME International},
  issn = {1050-0472, 1528-9001},
  doi = {10.1115/1.2826123},
  urldate = {2025-05-23},
  abstract = {This paper presents a knowledge-based systems approach to the automation of the conceptual synthesis of mechanisms. The system utilizes a procedure for synthesizing design alternatives based on the principle of separation of structure from function. This principle in turn resolves the problem of knowledge representation of design alternatives through the use of graph structures which are then evaluated using a set of heuristic rules. The expert system presented in this paper has been implemented and tested for the conceptual synthesis of variable-stroke engines and robot-hands kinematic structures. The system has shown the capability of producing numerous design alternatives for these two applications, and has provided consistent results based on the evaluation rules. It has also provided the designer with immediate feedback on the viability of any given design alternative and the reasons behind that decision.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/UKB6PX4S/Chew et al. - 1995 - Kinematic Structural Synthesis of Mechanisms Using Knowledge-Based Systems.pdf}
}

@article{deshpandeDeepCPGPoliciesRobot2023,
  title = {{{DeepCPG Policies}} for {{Robot Locomotion}}},
  author = {Deshpande, Aditya M. and Hurd, Eric and Minai, Ali A and Kumar, Manish},
  year = {2023},
  month = dec,
  journal = {IEEE Transactions on Cognitive and Developmental Systems},
  volume = {15},
  number = {4},
  pages = {2108--2121},
  issn = {2379-8939},
  doi = {10.1109/TCDS.2023.3250393},
  urldate = {2025-06-11},
  abstract = {Central pattern generators (CPGs) form the neural basis of the observed rhythmic behaviors for locomotion in legged animals. The CPG dynamics organized into networks allow the emergence of complex locomotor behaviors. In this work, we take this inspiration for developing walking behaviors in multilegged robots. We present novel DeepCPG policies that embed CPGs as a layer in a larger neural network and facilitate end-to-end learning of locomotion behaviors in deep reinforcement learning (DRL) setup. We demonstrate the effectiveness of this approach on physics engine-based insectoid robots. We show that, compared to traditional approaches, DeepCPG policies allow sample-efficient end-to-end learning of effective locomotion strategies even in the case of high-dimensional sensor spaces (vision). We scale the DeepCPG policies using a modular robot configuration and multiagent DRL. Our results suggest that gradual complexification with embedded priors of these policies in a modular fashion could achieve nontrivial sensor and motor integration on a robot platform. These results also indicate the efficacy of bootstrapping more complex intelligent systems from simpler ones based on biological principles. Finally, we present the experimental results for a proof-of-concept insectoid robot system for which DeepCPG learned policies initially using the simulation engine and these were afterward transferred to real-world robots without any additional fine-tuning.},
  file = {/home/vaishnavahari/Zotero/storage/2PNVU5BX/Deshpande et al. - 2023 - DeepCPG Policies for Robot Locomotion.pdf}
}

@article{doncieuxEvolutionaryRoboticsWhat2015,
  title = {Evolutionary {{Robotics}}: {{What}}, {{Why}}, and {{Where}} To},
  shorttitle = {Evolutionary {{Robotics}}},
  author = {Doncieux, Stephane and Bredeche, Nicolas and Mouret, Jean-Baptiste and Eiben, Agoston E. (Gusz)},
  year = {2015},
  month = mar,
  journal = {Frontiers in Robotics and AI},
  volume = {2},
  publisher = {Frontiers},
  issn = {2296-9144},
  doi = {10.3389/frobt.2015.00004},
  urldate = {2025-05-23},
  abstract = {Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help to address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper, we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.},
  langid = {english},
  keywords = {embodied intelligence,evolutionary algorithms,Evolutionary Biology,Evolutionary Robotics,Robotics},
  file = {/home/vaishnavahari/Zotero/storage/XQ9NF4GN/Doncieux et al. - 2015 - Evolutionary Robotics What, Why, and Where to.pdf}
}

@misc{earleHierarchicalSubtaskDiscovery2017,
  title = {Hierarchical {{Subtask Discovery With Non-Negative Matrix Factorization}}},
  author = {Earle, Adam C. and Saxe, Andrew M. and Rosman, Benjamin},
  year = {2017},
  month = aug,
  number = {arXiv:1708.00463},
  eprint = {1708.00463},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1708.00463},
  urldate = {2025-05-07},
  abstract = {Hierarchical reinforcement learning methods offer a powerful means of planning flexible behavior in complicated domains. However, learning an appropriate hierarchical decomposition of a domain into subtasks remains a substantial challenge. We present a novel algorithm for subtask discovery, based on the recently introduced multitask linearly-solvable Markov decision process (MLMDP) framework. The MLMDP can perform never-before-seen tasks by representing them as a linear combination of a previously learned basis set of tasks. In this setting, the subtask discovery problem can naturally be posed as finding an optimal low-rank approximation of the set of tasks the agent will face in a domain. We use non-negative matrix factorization to discover this minimal basis set of tasks, and show that the technique learns intuitive decompositions in a variety of domains. Our method has several qualitatively desirable features: it is not limited to learning subtasks with single goal states, instead learning distributed patterns of preferred states; it learns qualitatively different hierarchical decompositions in the same domain depending on the ensemble of tasks the agent will face; and it may be straightforwardly iterated to obtain deeper hierarchical decompositions.},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/IBHWVXTV/Earle et al. - 2017 - Hierarchical Subtask Discovery With Non-Negative Matrix Factorization.pdf;/home/vaishnavahari/Zotero/storage/47RFS9TU/1708.html}
}

@misc{frauenknechtTrustModelWhere2024,
  title = {Trust the {{Model Where It Trusts Itself}} -- {{Model-Based Actor-Critic}} with {{Uncertainty-Aware Rollout Adaption}}},
  author = {Frauenknecht, Bernd and Eisele, Artur and Subhasish, Devdutt and Solowjow, Friedrich and Trimpe, Sebastian},
  year = {2024},
  month = jun,
  number = {arXiv:2405.19014},
  eprint = {2405.19014},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2405.19014},
  urldate = {2025-05-31},
  abstract = {Dyna-style model-based reinforcement learning (MBRL) combines model-free agents with predictive transition models through model-based rollouts. This combination raises a critical question: 'When to trust your model?'; i.e., which rollout length results in the model providing useful data? Janner et al. (2019) address this question by gradually increasing rollout lengths throughout the training. While theoretically tempting, uniform model accuracy is a fallacy that collapses at the latest when extrapolating. Instead, we propose asking the question 'Where to trust your model?'. Using inherent model uncertainty to consider local accuracy, we obtain the Model-Based Actor-Critic with Uncertainty-Aware Rollout Adaption (MACURA) algorithm. We propose an easy-to-tune rollout mechanism and demonstrate substantial improvements in data efficiency and performance compared to state-of-the-art deep MBRL methods on the MuJoCo benchmark.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/home/vaishnavahari/Zotero/storage/8SWSZAWL/Frauenknecht et al. - 2024 - Trust the Model Where It Trusts Itself -- Model-Based Actor-Critic with Uncertainty-Aware Rollout Ad.pdf}
}

@inproceedings{haarnojaLatentSpacePolicies2018,
  title = {Latent {{Space Policies}} for {{Hierarchical Reinforcement Learning}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  year = {2018},
  month = jul,
  pages = {1851--1860},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-05-07},
  abstract = {We address the problem of learning hierarchical deep neural network policies for reinforcement learning. In contrast to methods that explicitly restrict or cripple lower layers of a hierarchy to force them to use higher-level modulating signals, each layer in our framework is trained to directly solve the task, but acquires a range of diverse strategies via a maximum entropy reinforcement learning objective. Each layer is also augmented with latent random variables, which are sampled from a prior distribution during the training of that layer. The maximum entropy objective causes these latent variables to be incorporated into the layer's policy, and the higher level layer can directly control the behavior of the lower layer through this latent space. Furthermore, by constraining the mapping from latent variables to actions to be invertible, higher layers retain full expressivity: neither the higher layers nor the lower layers are constrained in their behavior. Our experimental evaluation demonstrates that we can improve on the performance of single-layer policies on standard benchmark tasks simply by adding additional layers, and that our method can solve more complex sparse-reward tasks by learning higher-level policies on top of high-entropy skills optimized for simple low-level objectives.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/J7L4ND38/Haarnoja et al. - 2018 - Latent Space Policies for Hierarchical Reinforcement Learning.pdf;/home/vaishnavahari/Zotero/storage/MM87QYTH/Supplementary - Haarnoja et al. - 2018 - Latent Space Policies for Hierarchical Reinforcement Learning.pdf}
}

@article{haarnojaReinforcementLearningDeep,
  title = {Reinforcement {{Learning}} with {{Deep Energy-Based Policies}}},
  author = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  abstract = {We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actorcritic methods, which can be viewed performing approximate inference on the corresponding energy-based model.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/VAECUY3T/Haarnoja et al. - Reinforcement Learning with Deep Energy-Based Policies.pdf}
}

@inproceedings{hongStructureAwareTransformerPolicy2021,
  title = {Structure-{{Aware Transformer Policy}} for {{Inhomogeneous Multi-Task Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Hong, Sunghoon and Yoon, Deunsol and Kim, Kee-Eung},
  year = {2021},
  month = oct,
  urldate = {2025-05-26},
  abstract = {Modular Reinforcement Learning, where the agent is assumed to be morphologically structured as a graph, for example composed of limbs and joints, aims to learn a policy that is transferable to a structurally similar but different agent. Compared to traditional Multi-Task Reinforcement Learning, this promising approach allows us to cope with inhomogeneous tasks where the state and action space dimensions differ across tasks. Graph Neural Networks are a natural model for representing the pertinent policies, but a recent work has shown that their multi-hop message passing mechanism is not ideal for conveying important information to other modules and thus a transformer model without morphological information was proposed. In this work, we argue that the morphological information is still very useful and propose a transformer policy model that effectively encodes such information. Specifically, we encode the morphological information in terms of the traversal-based positional embedding and the graph-based relational embedding. We empirically show that the morphological information is crucial for modular reinforcement learning, substantially outperforming prior state-of-the-art methods on multi-task learning as well as transfer learning settings with different state and action space dimensions.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/MGZALL7B/Hong et al. - 2021 - Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning.pdf}
}

@article{hutsebaut-buysseHierarchicalReinforcementLearning2022,
  title = {Hierarchical {{Reinforcement Learning}}: {{A Survey}} and {{Open Research Challenges}}},
  shorttitle = {Hierarchical {{Reinforcement Learning}}},
  author = {{Hutsebaut-Buysse}, Matthias and Mets, Kevin and Latr{\'e}, Steven},
  year = {2022},
  month = mar,
  journal = {Machine Learning and Knowledge Extraction},
  volume = {4},
  number = {1},
  pages = {172--221},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2504-4990},
  doi = {10.3390/make4010009},
  urldate = {2025-05-07},
  abstract = {Reinforcement learning (RL) allows an agent to solve sequential decision-making problems by interacting with an environment in a trial-and-error fashion. When these environments are very complex, pure random exploration of possible solutions often fails, or is very sample inefficient, requiring an unreasonable amount of interaction with the environment. Hierarchical reinforcement learning (HRL) utilizes forms of temporal- and state-abstractions in order to tackle these challenges, while simultaneously paving the road for behavior reuse and increased interpretability of RL systems. In this survey paper we first introduce a selection of problem-specific approaches, which provided insight in how to utilize often handcrafted abstractions in specific task settings. We then introduce the Options framework, which provides a more generic approach, allowing abstractions to be discovered and learned semi-automatically. Afterwards we introduce the goal-conditional approach, which allows sub-behaviors to be embedded in a continuous space. In order to further advance the development of HRL agents, capable of simultaneously learning abstractions and how to use them, solely from interaction with complex high dimensional environments, we also identify a set of promising research directions.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {\5,\read},
  file = {/home/vaishnavahari/Zotero/storage/94V8FYEY/Hutsebaut-Buysse et al. - 2022 - Hierarchical Reinforcement Learning A Survey and Open Research Challenges.pdf}
}

@article{jaquierTransferLearningRobotics2025,
  title = {Transfer Learning in Robotics: {{An}} Upcoming Breakthrough? {{A}} Review of Promises and Challenges},
  shorttitle = {Transfer Learning in Robotics},
  author = {Jaquier, No{\'e}mie and Welle, Michael C and Gams, Andrej and Yao, Kunpeng and Fichera, Bernardo and Billard, Aude and Ude, Ale{\v s} and Asfour, Tamim and Kragic, Danica},
  year = {2025},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {3},
  pages = {465--485},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241273565},
  urldate = {2025-05-26},
  abstract = {Transfer learning is a conceptually-enticing paradigm in pursuit of truly intelligent embodied agents. The core concept---reusing prior knowledge to learn in and from novel situations---is successfully leveraged by humans to handle novel situations. In recent years, transfer learning has received renewed interest from the community from different perspectives, including imitation learning, domain adaptation, and transfer of experience from simulation to the real world, among others. In this paper, we unify the concept of transfer learning in robotics and provide the first taxonomy of its kind considering the key concepts of robot, task, and environment. Through a review of the promises and challenges in the field, we identify the need of transferring at different abstraction levels, the need of quantifying the transfer gap and the quality of transfer, as well as the dangers of negative transfer. Via this position paper, we hope to channel the effort of the community towards the most significant roadblocks to realize the full potential of transfer learning in robotics.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/CN6DBQAK/Jaquier et al. - 2025 - Transfer learning in robotics An upcoming breakthrough A review of promises and challenges.pdf}
}

@article{jelisavcicRealWorldEvolutionRobot2017,
  title = {Real-{{World Evolution}} of {{Robot Morphologies}}: {{A Proof}} of {{Concept}}},
  shorttitle = {Real-{{World Evolution}} of {{Robot Morphologies}}},
  author = {Jelisavcic, Milan and De Carlo, Matteo and Hupkes, Elte and Eustratiadis, Panagiotis and Orlowski, Jakub and Haasdijk, Evert and Auerbach, Joshua E. and Eiben, A. E.},
  year = {2017},
  month = may,
  journal = {Artificial Life},
  volume = {23},
  number = {2},
  pages = {206--235},
  issn = {1064-5462, 1530-9185},
  doi = {10.1162/ARTL_a_00231},
  urldate = {2025-06-11},
  abstract = {Evolutionary robotics using real hardware has been almost exclusively restricted to evolving robot controllers, but the technology for evolvable morphologies is advancing quickly. We discuss a proof-of-concept study to demonstrate real robots that can reproduce. Following a general system plan, we implement a robotic habitat that contains all system components in the simplest possible form. We create an initial population of two robots and run a complete life cycle, resulting in a new robot, parented by the first two. Even though the individual steps are simplified to the maximum, the whole system validates the underlying concepts and provides a generic workflow for the creation of more complex incarnations. This hands-on experience provides insights and helps us elaborate on interesting research directions for future development.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/M7A953CX/Jelisavcic et al. - 2017 - Real-World Evolution of Robot Morphologies A Proof of Concept.pdf}
}

@inproceedings{mehrotraExtractingHierarchiesSearch2017,
  title = {Extracting {{Hierarchies}} of {{Search Tasks}} \& {{Subtasks}} via a {{Bayesian Nonparametric Approach}}},
  booktitle = {Proceedings of the 40th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Mehrotra, Rishabh and Yilmaz, Emine},
  year = {2017},
  month = aug,
  series = {{{SIGIR}} '17},
  pages = {285--294},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3077136.3080823},
  urldate = {2025-05-07},
  abstract = {A significant amount of search queries originate from some real world information need or tasks [13]. In order to improve the search experience of the end users, it is important to have accurate representations of tasks. As a result, significant amount of research has been devoted to extracting proper representations of tasks in order to enable search systems to help users complete their tasks, as well as providing the end user with better query suggestions [9], for better recommendations [41], for satisfaction prediction [36] and for improved personalization in terms of tasks [24, 38]. Most existing task extraction methodologies focus on representing tasks as flat structures. However, tasks often tend to have multiple subtasks associated with them and a more naturalistic representation of tasks would be in terms of a hierarchy, where each task can be composed of multiple (sub)tasks. To this end, we propose an efficient Bayesian nonparametric model for extracting hierarchies of such tasks \&amp; subtasks. We evaluate our method based on real world query log data both through quantitative and crowdsourced experiments and highlight the importance of considering task/subtask hierarchies.},
  isbn = {978-1-4503-5022-8},
  file = {/home/vaishnavahari/Zotero/storage/8I9ZSHA3/Mehrotra and Yilmaz - 2017 - Extracting Hierarchies of Search Tasks & Subtasks via a Bayesian Nonparametric Approach.pdf}
}

@inproceedings{mounsifUniversalNoticeNetwork2019,
  title = {Universal {{Notice Network}}: {{Transferable Knowledge Among Agents}}},
  shorttitle = {Universal {{Notice Network}}},
  booktitle = {2019 6th {{International Conference}} on {{Control}}, {{Decision}} and {{Information Technologies}} ({{CoDIT}})},
  author = {Mounsif, Mehdi and Lengagne, Sebastien and Thuilot, Benoit and Adouane, Lounis},
  year = {2019},
  month = apr,
  pages = {563--568},
  issn = {2576-3555},
  doi = {10.1109/CoDIT.2019.8820403},
  urldate = {2025-05-26},
  abstract = {Being able to learn and transfer skills from one agent to another is a fundamental feature in constructing even more intelligent behaviors. In this paper, we introduce a new kind of architecture and information pipeline that aims to enable the transmission of skills from one robot to one or several others. The Universal Notice Network (UNN) originality lies in the fact that it clearly distinguishes knowledge necessary to solve the task from the agent intrinsic perceptions and capabilities, hence increasing its reusability and its potential transmission to other agents. In various experiments, focusing on manipulation and comanipulation tasks in original environments, we demonstrate the capabilities of the proposed method that takes advantage of reinforcement learning algorithms and domain knowledge, such as forward geometric model and inverse kinematics. In particular, we show that a learned UNN through the interactions of an agent with its environment is transmissible to other agents, conserving a similar perfomance level.},
  file = {/home/vaishnavahari/Zotero/storage/E6UT6BV2/Mounsif et al. - 2019 - Universal Notice Network Transferable Knowledge Among Agents.pdf}
}

@article{mruthyunjayaComputerizedMethodologyStructural1984,
  title = {A Computerized Methodology for Structural Synthesis of Kinematic Chains: {{Part}} 3--- Application to the New Case of 10-Link, Three- Freedom Chains},
  shorttitle = {A Computerized Methodology for Structural Synthesis of Kinematic Chains},
  author = {Mruthyunjaya, T. S},
  year = {1984},
  month = jan,
  journal = {Mechanism and Machine Theory},
  volume = {19},
  number = {6},
  pages = {507--530},
  issn = {0094-114X},
  doi = {10.1016/0094-114X(84)90057-0},
  urldate = {2025-05-23},
  abstract = {The unified computer program for structural synthesis and analysis developed in Part 1 has been employed to derive the new and complete collection of 97 10-link, three-freedom simple-jointed kinematic chains. The program shows that of these chains, 3 have total freedom, 70 have partial freedom and the remaining 24 have fractionated freedom and that the 97 chains yield a total of 676 distinct mechanisms. Zusammenfassung In der vorliegenden Arbeit wird das im erstern Teil entwickelte Rechenpprogramm f{\"u}r die strukturelle Synthese und Analyse auf den neuen Fall der 10-gliedrigen einfachgelenkigen Ketten mit drei Freiheitsgraden angewandt. Das Programm zeigt, dass es in dieser Kategorie 97 verschiedene Ketten gibt. Es zeigt auch, da{$\beta$} unter den Ketten, drei Ketten volle Freiheit, 70 Ketten Teilfreiheit und 24 Ketten fractionierte Freiheit haben, und die 97 Ketten ergeben zusammen 676 verschiedene Mechanismen.},
  file = {/home/vaishnavahari/Zotero/storage/8QXZ5PD3/Mruthyunjaya - 1984 - A computerized methodology for structural synthesis of kinematic chains Part 3— application to the.pdf;/home/vaishnavahari/Zotero/storage/NI8HFABL/0094114X84900570.html}
}

@article{naya-varelaMorphologicalDevelopmentRobotic2021,
  title = {Morphological {{Development}} in {{Robotic Learning}}: {{A Survey}}},
  shorttitle = {Morphological {{Development}} in {{Robotic Learning}}},
  author = {{Naya-Varela}, Mart{\'i}n and Fa{\'i}{\~n}a, Andr{\'e}s and Duro, Richard J.},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Cognitive and Developmental Systems},
  volume = {13},
  number = {4},
  pages = {750--768},
  issn = {2379-8939},
  doi = {10.1109/TCDS.2021.3052548},
  urldate = {2025-06-11},
  abstract = {Humans and animals undergo morphological development (MD) processes from infancy to adulthood that have been shown to facilitate learning. However, most of the work on developmental robotics (DRs) considers fixed morphologies, addressing only the development of the cognitive system of the robots. This article aims to provide a survey of the work that is being carried out within the relatively new field of MD in robots. In particular, it contemplates MD as the changes that occur in the properties of the joints, links and sensors of a robot during its lifetime and focuses on the work carried out by different authors to try to determine their influence on robot learning. To this end, walking, reaching, grasping and vocalization have been identified as the four most representative tasks addressed in the field, clustering the work of the different authors around them. The approach followed is multidisciplinary, discussing the relationships among DRs, embodied artificial intelligence and developmental psychology in humans in general, as well as for each of the tasks, and providing an overview of the many avenues of research that are still open in this field.},
  file = {/home/vaishnavahari/Zotero/storage/UFZUBL2X/Naya-Varela et al. - 2021 - Morphological Development in Robotic Learning A Survey.pdf}
}

@misc{pandeyAccessibleSurveyEvolutionary2022,
  title = {Accessible {{Survey}} of {{Evolutionary Robotics}} and {{Potential Future Research Directions}}},
  author = {Pandey, Hari Mohan},
  year = {2022},
  month = oct,
  number = {arXiv:2210.11704},
  eprint = {2210.11704},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.11704},
  urldate = {2025-05-23},
  abstract = {This paper reviews various Evolutionary Approaches applied to the domain of Evolutionary Robotics with the intention of resolving difficult problems in the areas of robotic design and control. Evolutionary Robotics is a fast-growing field that has attracted substantial research attention in recent years. The paper thus collates recent findings along with some anticipated applications. The reviewed literature is organized systematically to give a categorical overview of recent developments and is presented in tabulated form for quick reference. We discuss the outstanding potentialities and challenges that exist in robotics from an ER perspective, with the belief that these will be have the capacity to be addressed in the near future via the application of evolutionary approaches. The primary objective of this study is to explore the applicability of Evolutionary Approaches in robotic application development. We believe that this study will enable the researchers to utilize Evolutionary Approaches to solve complex outstanding problems in robotics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/home/vaishnavahari/Zotero/storage/L7JWSS8F/Pandey - 2022 - Accessible Survey of Evolutionary Robotics and Potential Future Research Directions.pdf;/home/vaishnavahari/Zotero/storage/TWUNHUBP/2210.html}
}

@misc{parakhAnyBodyBenchmarkSuite2025,
  title = {{{AnyBody}}: {{A Benchmark Suite}} for {{Cross-Embodiment Manipulation}}},
  shorttitle = {{{AnyBody}}},
  author = {Parakh, Meenal and Kirchmeyer, Alexandre and Han, Beining and Deng, Jia},
  year = {2025},
  month = may,
  number = {arXiv:2505.14986},
  eprint = {2505.14986},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.14986},
  urldate = {2025-06-11},
  abstract = {Generalizing control policies to novel embodiments remains a fundamental challenge in enabling scalable and transferable learning in robotics. While prior works have explored this in locomotion, a systematic study in the context of manipulation tasks remains limited, partly due to the lack of standardized benchmarks. In this paper, we introduce a benchmark for learning cross-embodiment manipulation, focusing on two foundational tasks-reach and push-across a diverse range of morphologies. The benchmark is designed to test generalization along three axes: interpolation (testing performance within a robot category that shares the same link structure), extrapolation (testing on a robot with a different link structure), and composition (testing on combinations of link structures). On the benchmark, we evaluate the ability of different RL policies to learn from multiple morphologies and to generalize to novel ones. Our study aims to answer whether morphology-aware training can outperform single-embodiment baselines, whether zero-shot generalization to unseen morphologies is feasible, and how consistently these patterns hold across different generalization regimes. The results highlight the current limitations of multi-embodiment learning and provide insights into how architectural and training design choices influence policy generalization.},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/7PYGKG67/Parakh et al. - 2025 - AnyBody A Benchmark Suite for Cross-Embodiment Manipulation.pdf;/home/vaishnavahari/Zotero/storage/XZUM75BY/2505.html}
}

@article{pateriaHierarchicalReinforcementLearning2021,
  title = {Hierarchical {{Reinforcement Learning}}: {{A Comprehensive Survey}}},
  shorttitle = {Hierarchical {{Reinforcement Learning}}},
  author = {Pateria, Shubham and Subagdja, Budhitama and Tan, Ah-hwee and Quek, Chai},
  year = {2021},
  month = jun,
  journal = {ACM Comput. Surv.},
  volume = {54},
  number = {5},
  pages = {109:1--109:35},
  issn = {0360-0300},
  doi = {10.1145/3453160},
  urldate = {2025-05-07},
  abstract = {Hierarchical Reinforcement Learning (HRL) enables autonomous decomposition of challenging long-horizon decision-making tasks into simpler subtasks. During the past years, the landscape of HRL research has grown profoundly, resulting in copious approaches. A comprehensive overview of this vast landscape is necessary to study HRL in an organized manner. We provide a survey of the diverse HRL approaches concerning the challenges of learning hierarchical policies, subtask discovery, transfer learning, and multi-agent learning using HRL. The survey is presented according to a novel taxonomy of the approaches. Based on the survey, a set of important open problems is proposed to motivate the future research in HRL. Furthermore, we outline a few suitable task domains for evaluating the HRL approaches and a few interesting examples of the practical applications of HRL in the Supplementary Material.},
  file = {/home/vaishnavahari/Zotero/storage/ZSA9KFME/Pateria et al. - 2021 - Hierarchical Reinforcement Learning A Comprehensive Survey.pdf}
}

@misc{pathakLearningControlSelfAssembling2019,
  title = {Learning to {{Control Self-Assembling Morphologies}}: {{A Study}} of {{Generalization}} via {{Modularity}}},
  shorttitle = {Learning to {{Control Self-Assembling Morphologies}}},
  author = {Pathak, Deepak and Lu, Chris and Darrell, Trevor and Isola, Phillip and Efros, Alexei A.},
  year = {2019},
  month = nov,
  number = {arXiv:1902.05546},
  eprint = {1902.05546},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.05546},
  urldate = {2025-06-11},
  abstract = {Contemporary sensorimotor learning approaches typically start with an existing complex agent (e.g., a robotic arm), which they learn to control. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to dynamically self-assemble into composite bodies while also learning to coordinate their behavior to control these bodies. Each primitive agent consists of a limb with a motor attached at one end. Limbs may choose to link up to form collectives. When a limb initiates a link-up action, and there is another limb nearby, the latter is magnetically connected to the 'parent' limb's motor. This forms a new single agent, which may further link with other agents. In this way, complex morphologies can emerge, controlled by a policy whose architecture is in explicit correspondence with the morphology. We evaluate the performance of these dynamic and modular agents in simulated environments. We demonstrate better generalization to test-time changes both in the environment, as well as in the structure of the agent, compared to static and monolithic baselines. Project video and code are available at https://pathak22.github.io/modular-assemblies/},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/HBINIVDR/Pathak et al. - 2019 - Learning to Control Self-Assembling Morphologies A Study of Generalization via Modularity.pdf;/home/vaishnavahari/Zotero/storage/ZNUDC4RH/1902.html}
}

@misc{qiuIdentifyingSelectionsUnsupervised2024,
  title = {Identifying {{Selections}} for {{Unsupervised Subtask Discovery}}},
  author = {Qiu, Yiwen and Zheng, Yujia and Zhang, Kun},
  year = {2024},
  month = oct,
  number = {arXiv:2410.21616},
  eprint = {2410.21616},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.21616},
  urldate = {2025-05-07},
  abstract = {When solving long-horizon tasks, it is intriguing to decompose the high-level task into subtasks. Decomposing experiences into reusable subtasks can improve data efficiency, accelerate policy generalization, and in general provide promising solutions to multi-task reinforcement learning and imitation learning problems. However, the concept of subtasks is not sufficiently understood and modeled yet, and existing works often overlook the true structure of the data generation process: subtasks are the results of a \${\textbackslash}textit\{selection\}\$ mechanism on actions, rather than possible underlying confounders or intermediates. Specifically, we provide a theory to identify, and experiments to verify the existence of selection variables in such data. These selections serve as subgoals that indicate subtasks and guide policy. In light of this idea, we develop a sequential non-negative matrix factorization (seq- NMF) method to learn these subgoals and extract meaningful behavior patterns as subtasks. Our empirical results on a challenging Kitchen environment demonstrate that the learned subtasks effectively enhance the generalization to new tasks in multi-task imitation learning scenarios. The codes are provided at https://anonymous.4open.science/r/Identifying{\textbackslash}\_Selections{\textbackslash}\_for{\textbackslash}\_Unsupervised{\textbackslash}\_Subtask{\textbackslash}\_Discovery/README.md.},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/EMC76FF9/Qiu et al. - 2024 - Identifying Selections for Unsupervised Subtask Discovery.pdf;/home/vaishnavahari/Zotero/storage/27MS2I6V/2410.html}
}

@article{suttonMDPsSemiMDPsFramework1999,
  title = {Between {{MDPs}} and Semi-{{MDPs}}: {{A}} Framework for Temporal Abstraction in Reinforcement Learning},
  shorttitle = {Between {{MDPs}} and Semi-{{MDPs}}},
  author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
  year = {1999},
  month = aug,
  journal = {Artificial Intelligence},
  volume = {112},
  number = {1-2},
  pages = {181--211},
  issn = {00043702},
  doi = {10.1016/S0004-3702(99)00052-1},
  urldate = {2025-04-21},
  abstract = {Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options---closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macroutility problem.  1999 Published by Elsevier Science B.V. All rights reserved.},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/M5JC2JBL/Sutton et al. - 1999 - Between MDPs and semi-MDPs A framework for temporal abstraction in reinforcement learning.pdf}
}

@inproceedings{vezhnevetsFeUdalNetworksHierarchical2017,
  title = {{{FeUdal Networks}} for {{Hierarchical Reinforcement Learning}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  year = {2017},
  month = jul,
  pages = {3540--3549},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-05-07},
  abstract = {We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a slower time scale and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/6Y8D72T8/Vezhnevets et al. - 2017 - FeUdal Networks for Hierarchical Reinforcement Learning.pdf}
}

@inproceedings{vosyliusWhereStartTransferring2023,
  title = {Where {{To Start}}? {{Transferring Simple Skills}} to {{Complex Environments}}},
  shorttitle = {Where {{To Start}}?},
  booktitle = {Proceedings of {{The}} 6th {{Conference}} on {{Robot Learning}}},
  author = {Vosylius, Vitalis and Johns, Edward},
  year = {2023},
  month = mar,
  pages = {471--481},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-05-26},
  abstract = {Robot learning provides a number of ways to teach robots simple skills, such as grasping. However, these skills are usually trained in open, clutter-free environments, and therefore would likely cause undesirable collisions in more complex, cluttered environments. In this work, we introduce an affordance model based on a graph representation of an environment, which is optimised during deployment to find suitable robot configurations to start a skill from, such that the skill can be executed without any collisions. We demonstrate that our method can generalise a priori acquired skills to previously unseen cluttered and constrained environments, in simulation and in the real world, for both a grasping and a placing task.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/7PTWVZZB/Vosylius and Johns - 2023 - Where To Start Transferring Simple Skills to Complex Environments.pdf;/home/vaishnavahari/Zotero/storage/TCJITISL/Vosylius and Johns - 2023 - Where To Start Transferring Simple Skills to Complex Environments.pdf}
}

@article{wangReinforcementLearningTransfer2014,
  title = {Reinforcement Learning Transfer Based on Subgoal Discovery and Subtask Similarity},
  author = {Wang, Hao and Fan, Shunguo and Song, Jinhua and Gao, Yang and Chen, Xingguo},
  year = {2014},
  month = jul,
  journal = {IEEE/CAA Journal of Automatica Sinica},
  volume = {1},
  number = {3},
  pages = {257--266},
  issn = {2329-9274},
  doi = {10.1109/JAS.2014.7004683},
  urldate = {2025-05-07},
  abstract = {This paper studies the problem of transfer learning in the context of reinforcement learning. We propose a novel transfer learning method that can speed up reinforcement learning with the aid of previously learnt tasks. Before performing extensive learning episodes, our method attempts to analyze the learning task via some exploration in the environment, and then attempts to reuse previous learning experience whenever it is possible and appropriate. In particular, our proposed method consists of four stages: 1) subgoal discovery, 2) option construction, 3) similarity searching, and 4) option reusing. Especially, in order to fulfill the task of identifying similar options, we propose a novel similarity measure between options, which is built upon the intuition that similar options have similar state-action probabilities. We examine our algorithm using extensive experiments, comparing it with existing methods. The results show that our method outperforms conventional non-transfer reinforcement learning algorithms, as well as existing transfer learning methods, by a wide margin.},
  file = {/home/vaishnavahari/Zotero/storage/Y7Q7LBE9/Wang et al. - 2014 - Reinforcement learning transfer based on subgoal discovery and subtask similarity.pdf}
}

@article{whitmanLearningModularRobot2023,
  title = {Learning {{Modular Robot Control Policies}}},
  author = {Whitman, Julian and Travers, Matthew and Choset, Howie},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {4095--4113},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3284362},
  urldate = {2025-05-26},
  abstract = {Modular robots can be rearranged into a new design, perhaps each day, to handle a wide variety of tasks by forming a customized robot for each new task. However, reconfiguring just the mechanism is not sufficient: each design also requires its own unique control policy. One could craft a policy from scratch for each new design, but such an approach is not scalable, especially given the large number of designs that can be generated from even a small set of modules. Instead, we create a modular policy framework where the policy structure is conditioned on the hardware arrangement, and use just one training process to create a policy that controls a wide variety of designs. Our approach leverages the fact that the kinematics of a modular robot can be represented as a design graph, with nodes as modules and edges as connections between them. Given a robot, its design graph is used to create a policy graph with the same structure, where each node contains a deep neural network, and modules of the same type share knowledge via shared parameters (e.g., all legs on a hexapod share the same network parameters). We developed a model-based reinforcement learning algorithm, interleaving model learning and trajectory optimization to train the policy. We show the modular policy generalizes to a large number of designs that were not seen during training without any additional learning. Finally, we demonstrate the policy controlling a variety of designs to locomote with both simulated and real robots.},
  file = {/home/vaishnavahari/Zotero/storage/RVNXKBK9/Whitman et al. - 2023 - Learning Modular Robot Control Policies.pdf}
}

@article{zhangMaterialsTerminologyKnowledge2024,
  title = {A Materials Terminology Knowledge Graph Automatically Constructed from Text Corpus},
  author = {Zhang, Yuwei and Chen, Fangyi and Liu, Zeyi and Ju, Yunzhuo and Cui, Dongliang and Zhu, Jinyi and Jiang, Xue and Guo, Xi and He, Jie and Zhang, Lei and Zhang, Xiaotong and Su, Yanjing},
  year = {2024},
  month = jun,
  journal = {Scientific Data},
  volume = {11},
  number = {1},
  pages = {600},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-024-03448-0},
  urldate = {2025-05-23},
  abstract = {A scalable, reusable, and broad-coverage unified material knowledge representation shows its importance and will bring great benefits to data sharing among materials communities. A knowledge graph (KG) for materials terminology, which is a formal collection of term entities and relationships, is conceptually important to achieve this goal. In this work, we propose a KG for materials terminology, named Materials Genome Engineering Database Knowledge Graph (MGED-KG), which is automatically constructed from text corpus via natural language processing. MGED-KG is the most comprehensive KG for materials terminology in both Chinese and English languages, consisting of 8,660 terms and their explanations. It encompasses 11 principal categories, such as Metals, Composites, Nanomaterials, each with two or three levels of subcategories, resulting in a total of 235 distinct category labels. For further application, a knowledge web system based on MGED-KG is developed and shows its great power in improving data sharing efficiency from the aspects of query expansion, term, and data recommendation.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Computational science,Theory and computation},
  file = {/home/vaishnavahari/Zotero/storage/VYSJIJ6B/Zhang et al. - 2024 - A materials terminology knowledge graph automatically constructed from text corpus.pdf}
}
