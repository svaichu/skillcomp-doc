@article{alattasEvolutionaryModularRobotics2019,
  title = {Evolutionary {{Modular Robotics}}: {{Survey}} and {{Analysis}}},
  shorttitle = {Evolutionary {{Modular Robotics}}},
  author = {Alattas, Reem J. and Patel, Sarosh and Sobh, Tarek M.},
  year = {2019},
  month = sep,
  journal = {Journal of Intelligent \& Robotic Systems},
  volume = {95},
  number = {3},
  pages = {815--828},
  issn = {1573-0409},
  doi = {10.1007/s10846-018-0902-9},
  urldate = {2025-05-23},
  abstract = {This paper surveys various applications of artificial evolution in the field of modular robots. Evolutionary robotics aims to design autonomous adaptive robots automatically that can evolve to accomplish a specific task while adapting to environmental changes. A number of studies have demonstrated the feasibility of evolutionary algorithms for generating robotic control and morphology. However, a huge challenge faced was how to manufacture these robots. Therefore, modular robots were employed to simplify robotic evolution and their implementation in real hardware. Consequently, more research work has emerged on using evolutionary computation to design modular robots rather than using traditional hand design approaches in order to avoid cognition bias. These techniques have the potential of developing adaptive robots that can achieve tasks not fully understood by human designers. Furthermore, evolutionary algorithms were studied to generate global modular robotic behaviors including; self-assembly, self-reconfiguration, self-repair, and self-reproduction. These characteristics allow modular robots to explore unstructured and hazardous environments. In order to accomplish the aforementioned evolutionary modular robotic promises, this paper reviews current research on evolutionary robotics and modular robots. The motivation behind this work is to identify the most promising methods that can lead to developing autonomous adaptive robotic systems that require the minimum task related knowledge on the designer side.},
  langid = {english},
  keywords = {Bioinspired Robotics,Evolutionary robotics,Evolvability,Modular robots,Rehabilitation Robotics,Robotic Engineering,Robotics,Self-assembly,Self-reconfiguration,Self-repair,Self-reproduction,Social Robotics,Task-based design},
  file = {/home/vaishnavahari/Zotero/storage/ZMIKTV9D/Alattas et al. - 2019 - Evolutionary Modular Robotics Survey and Analysis.pdf}
}

@phdthesis{beaussantTransferLearningRobots2023,
  title = {Transfer Learning between Robots with State Abstraction},
  author = {Beaussant, Samuel},
  year = {2023},
  month = sep,
  urldate = {2025-05-26},
  abstract = {Despite numerous improvements regarding the effectiveness of ac\{rl\} methods in robotics, training from scratch still requires millions (or even tens of millions) of interactions with the environment to converge on high-performance behavior. In order to alleviate this huge need for data without losing performance, one promising avenue is ac\{tl\}. The aim of this thesis is to explore transfer learning in the context of RL, with the specific aim of transferring behaviors from one robot to another, even in the presence of morphological divergences or different state-action spaces. In particular, this thesis presents a process for reusing past knowledge acquired by a robot (source) on a task to accelerate (or even avoid) the learning process of a different robot (target) on the same task. The proposed method relies first on an unsupervised pre-training phase to learn a robot-agnostic latent space from trajectories collected on a set of robots. Then, it is possible to train a model within this space to solve a given task, in order to produce a task module that can be reused by any robot sharing this common feature space. In addition, this thesis tackles the problem of simulation-to-real-world adaptation when transferring a model trained in a simulator, with a focus on delay management, which is often overlook in the current literature. Indeed, we show that models oblivious to delay significantly drop in performance when tested on a physical robot, where the hardware and sensory system inevitably introduce delay. The approach developed is a simple but effective one for training agents to handle a user-defined range of delays. Through several robotic tasks and heterogeneous hardware platforms, both in simulation and on physical robots, this thesis shows the benefits of these approaches in terms of improved learning efficiency and performance. More specifically, we report zero-shot generalization in some instances, where performance after transfer is preserved. In the worst case, performance is recovered after a short adaptation on the target robot for a fraction of the training cost required to learn a policy with similar performance from scratch.},
  langid = {english},
  school = {Universit{\'e} Clermont Auvergne},
  file = {/home/vaishnavahari/Zotero/storage/N33BESSV/Beaussant - 2023 - Transfer learning between robots with state abstraction.pdf}
}

@article{bohlingerLearningRobotLocomotion,
  title = {Learning {{Robot Locomotion}} for {{Multiple Embodiments}}},
  author = {Bohlinger, Nico and Czechmanowski, Grzegorz and Krupka, Maciej and Kicki, Piotr and Walas, Krzysztof and Peters, Jan and Tateo, Davide},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/REA5X7D4/Bohlinger et al. - Learning Robot Locomotion for Multiple Embodiments.pdf}
}

@article{bongardEvolutionaryRobotics2013,
  title = {Evolutionary Robotics},
  author = {Bongard, Josh C.},
  year = {2013},
  month = aug,
  journal = {Commun. ACM},
  volume = {56},
  number = {8},
  pages = {74--83},
  issn = {0001-0782},
  doi = {10.1145/2493883},
  urldate = {2025-06-11},
  abstract = {Taking a biologically inspired approach to the design of autonomous, adaptive machines.},
  file = {/home/vaishnavahari/Zotero/storage/VAD44826/Bongard - 2013 - Evolutionary robotics.pdf}
}

@article{bongardMorphologicalChangeMachines2011,
  title = {Morphological Change in Machines Accelerates the Evolution of Robust Behavior},
  author = {Bongard, Josh},
  year = {2011},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {4},
  pages = {1234--1239},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1015390108},
  urldate = {2025-06-11},
  abstract = {Most animals exhibit significant neurological and morphological change throughout their lifetime. No robots to date, however, grow new morphological structure while behaving. This is due to technological limitations but also because it is unclear that morphological change provides a benefit to the acquisition of robust behavior in machines. Here I show that in evolving populations of simulated robots, if robots grow from anguilliform into legged robots during their lifetime in the early stages of evolution, and the anguilliform body plan is gradually lost during later stages of evolution, gaits are evolved for the final, legged form of the robot more rapidly---and the evolved gaits are more robust---compared to evolving populations of legged robots that do not transition through the anguilliform body plan. This suggests that morphological change, as well as the evolution of development, are two important processes that improve the automatic generation of robust behaviors for machines. It also provides an experimental platform for investigating the relationship between the evolution of development and robust behavior in biological organisms.},
  file = {/home/vaishnavahari/Zotero/storage/SZA2F9JP/Bongard - 2011 - Morphological change in machines accelerates the evolution of robust behavior.pdf}
}

@article{caoKnowledgeGraphEmbedding2024,
  title = {Knowledge {{Graph Embedding}}: {{A Survey}} from the {{Perspective}} of {{Representation Spaces}}},
  shorttitle = {Knowledge {{Graph Embedding}}},
  author = {Cao, Jiahang and Fang, Jinyuan and Meng, Zaiqiao and Liang, Shangsong},
  year = {2024},
  month = mar,
  journal = {ACM Comput. Surv.},
  volume = {56},
  number = {6},
  pages = {159:1--159:42},
  issn = {0360-0300},
  doi = {10.1145/3643806},
  urldate = {2025-05-26},
  abstract = {Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.},
  file = {/home/vaishnavahari/Zotero/storage/BSPJ32T7/Cao et al. - 2024 - Knowledge Graph Embedding A Survey from the Perspective of Representation Spaces.pdf}
}

@article{deshpandeDeepCPGPoliciesRobot2023,
  title = {{{DeepCPG Policies}} for {{Robot Locomotion}}},
  author = {Deshpande, Aditya M. and Hurd, Eric and Minai, Ali A and Kumar, Manish},
  year = {2023},
  month = dec,
  journal = {IEEE Transactions on Cognitive and Developmental Systems},
  volume = {15},
  number = {4},
  pages = {2108--2121},
  issn = {2379-8939},
  doi = {10.1109/TCDS.2023.3250393},
  urldate = {2025-06-11},
  abstract = {Central pattern generators (CPGs) form the neural basis of the observed rhythmic behaviors for locomotion in legged animals. The CPG dynamics organized into networks allow the emergence of complex locomotor behaviors. In this work, we take this inspiration for developing walking behaviors in multilegged robots. We present novel DeepCPG policies that embed CPGs as a layer in a larger neural network and facilitate end-to-end learning of locomotion behaviors in deep reinforcement learning (DRL) setup. We demonstrate the effectiveness of this approach on physics engine-based insectoid robots. We show that, compared to traditional approaches, DeepCPG policies allow sample-efficient end-to-end learning of effective locomotion strategies even in the case of high-dimensional sensor spaces (vision). We scale the DeepCPG policies using a modular robot configuration and multiagent DRL. Our results suggest that gradual complexification with embedded priors of these policies in a modular fashion could achieve nontrivial sensor and motor integration on a robot platform. These results also indicate the efficacy of bootstrapping more complex intelligent systems from simpler ones based on biological principles. Finally, we present the experimental results for a proof-of-concept insectoid robot system for which DeepCPG learned policies initially using the simulation engine and these were afterward transferred to real-world robots without any additional fine-tuning.},
  file = {/home/vaishnavahari/Zotero/storage/2PNVU5BX/Deshpande et al. - 2023 - DeepCPG Policies for Robot Locomotion.pdf}
}

@article{doncieuxEvolutionaryRoboticsWhat2015,
  title = {Evolutionary {{Robotics}}: {{What}}, {{Why}}, and {{Where}} To},
  shorttitle = {Evolutionary {{Robotics}}},
  author = {Doncieux, Stephane and Bredeche, Nicolas and Mouret, Jean-Baptiste and Eiben, Agoston E. (Gusz)},
  year = {2015},
  month = mar,
  journal = {Frontiers in Robotics and AI},
  volume = {2},
  publisher = {Frontiers},
  issn = {2296-9144},
  doi = {10.3389/frobt.2015.00004},
  urldate = {2025-05-23},
  abstract = {Evolutionary robotics applies the selection, variation, and heredity principles of natural evolution to the design of robots with embodied intelligence. It can be considered as a subfield of robotics that aims to create more robust and adaptive robots. A pivotal feature of the evolutionary approach is that it considers the whole robot at once, and enables the exploitation of robot features in a holistic manner. Evolutionary robotics can also be seen as an innovative approach to the study of evolution based on a new kind of experimentalism. The use of robots as a substrate can help to address questions that are difficult, if not impossible, to investigate through computer simulations or biological studies. In this paper, we consider the main achievements of evolutionary robotics, focusing particularly on its contributions to both engineering and biology. We briefly elaborate on methodological issues, review some of the most interesting findings, and discuss important open issues and promising avenues for future work.},
  langid = {english},
  keywords = {embodied intelligence,evolutionary algorithms,Evolutionary Biology,Evolutionary Robotics,Robotics},
  file = {/home/vaishnavahari/Zotero/storage/XQ9NF4GN/Doncieux et al. - 2015 - Evolutionary Robotics What, Why, and Where to.pdf}
}

@article{jaquierTransferLearningRobotics2025,
  title = {Transfer Learning in Robotics: {{An}} Upcoming Breakthrough? {{A}} Review of Promises and Challenges},
  shorttitle = {Transfer Learning in Robotics},
  author = {Jaquier, No{\'e}mie and Welle, Michael C and Gams, Andrej and Yao, Kunpeng and Fichera, Bernardo and Billard, Aude and Ude, Ale{\v s} and Asfour, Tamim and Kragic, Danica},
  year = {2025},
  month = mar,
  journal = {The International Journal of Robotics Research},
  volume = {44},
  number = {3},
  pages = {465--485},
  publisher = {SAGE Publications Ltd STM},
  issn = {0278-3649},
  doi = {10.1177/02783649241273565},
  urldate = {2025-05-26},
  abstract = {Transfer learning is a conceptually-enticing paradigm in pursuit of truly intelligent embodied agents. The core concept---reusing prior knowledge to learn in and from novel situations---is successfully leveraged by humans to handle novel situations. In recent years, transfer learning has received renewed interest from the community from different perspectives, including imitation learning, domain adaptation, and transfer of experience from simulation to the real world, among others. In this paper, we unify the concept of transfer learning in robotics and provide the first taxonomy of its kind considering the key concepts of robot, task, and environment. Through a review of the promises and challenges in the field, we identify the need of transferring at different abstraction levels, the need of quantifying the transfer gap and the quality of transfer, as well as the dangers of negative transfer. Via this position paper, we hope to channel the effort of the community towards the most significant roadblocks to realize the full potential of transfer learning in robotics.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/CN6DBQAK/Jaquier et al. - 2025 - Transfer learning in robotics An upcoming breakthrough A review of promises and challenges.pdf}
}

@article{jelisavcicRealWorldEvolutionRobot2017,
  title = {Real-{{World Evolution}} of {{Robot Morphologies}}: {{A Proof}} of {{Concept}}},
  shorttitle = {Real-{{World Evolution}} of {{Robot Morphologies}}},
  author = {Jelisavcic, Milan and De Carlo, Matteo and Hupkes, Elte and Eustratiadis, Panagiotis and Orlowski, Jakub and Haasdijk, Evert and Auerbach, Joshua E. and Eiben, A. E.},
  year = {2017},
  month = may,
  journal = {Artificial Life},
  volume = {23},
  number = {2},
  pages = {206--235},
  issn = {1064-5462, 1530-9185},
  doi = {10.1162/ARTL_a_00231},
  urldate = {2025-06-11},
  abstract = {Evolutionary robotics using real hardware has been almost exclusively restricted to evolving robot controllers, but the technology for evolvable morphologies is advancing quickly. We discuss a proof-of-concept study to demonstrate real robots that can reproduce. Following a general system plan, we implement a robotic habitat that contains all system components in the simplest possible form. We create an initial population of two robots and run a complete life cycle, resulting in a new robot, parented by the first two. Even though the individual steps are simplified to the maximum, the whole system validates the underlying concepts and provides a generic workflow for the creation of more complex incarnations. This hands-on experience provides insights and helps us elaborate on interesting research directions for future development.},
  langid = {english},
  file = {/home/vaishnavahari/Zotero/storage/M7A953CX/Jelisavcic et al. - 2017 - Real-World Evolution of Robot Morphologies A Proof of Concept.pdf}
}

@inproceedings{mounsifUniversalNoticeNetwork2019,
  title = {Universal {{Notice Network}}: {{Transferable Knowledge Among Agents}}},
  shorttitle = {Universal {{Notice Network}}},
  booktitle = {2019 6th {{International Conference}} on {{Control}}, {{Decision}} and {{Information Technologies}} ({{CoDIT}})},
  author = {Mounsif, Mehdi and Lengagne, Sebastien and Thuilot, Benoit and Adouane, Lounis},
  year = {2019},
  month = apr,
  pages = {563--568},
  issn = {2576-3555},
  doi = {10.1109/CoDIT.2019.8820403},
  urldate = {2025-05-26},
  abstract = {Being able to learn and transfer skills from one agent to another is a fundamental feature in constructing even more intelligent behaviors. In this paper, we introduce a new kind of architecture and information pipeline that aims to enable the transmission of skills from one robot to one or several others. The Universal Notice Network (UNN) originality lies in the fact that it clearly distinguishes knowledge necessary to solve the task from the agent intrinsic perceptions and capabilities, hence increasing its reusability and its potential transmission to other agents. In various experiments, focusing on manipulation and comanipulation tasks in original environments, we demonstrate the capabilities of the proposed method that takes advantage of reinforcement learning algorithms and domain knowledge, such as forward geometric model and inverse kinematics. In particular, we show that a learned UNN through the interactions of an agent with its environment is transmissible to other agents, conserving a similar perfomance level.},
  file = {/home/vaishnavahari/Zotero/storage/E6UT6BV2/Mounsif et al. - 2019 - Universal Notice Network Transferable Knowledge Among Agents.pdf}
}

@article{naya-varelaMorphologicalDevelopmentRobotic2021,
  title = {Morphological {{Development}} in {{Robotic Learning}}: {{A Survey}}},
  shorttitle = {Morphological {{Development}} in {{Robotic Learning}}},
  author = {{Naya-Varela}, Mart{\'i}n and Fa{\'i}{\~n}a, Andr{\'e}s and Duro, Richard J.},
  year = {2021},
  month = dec,
  journal = {IEEE Transactions on Cognitive and Developmental Systems},
  volume = {13},
  number = {4},
  pages = {750--768},
  issn = {2379-8939},
  doi = {10.1109/TCDS.2021.3052548},
  urldate = {2025-06-11},
  abstract = {Humans and animals undergo morphological development (MD) processes from infancy to adulthood that have been shown to facilitate learning. However, most of the work on developmental robotics (DRs) considers fixed morphologies, addressing only the development of the cognitive system of the robots. This article aims to provide a survey of the work that is being carried out within the relatively new field of MD in robots. In particular, it contemplates MD as the changes that occur in the properties of the joints, links and sensors of a robot during its lifetime and focuses on the work carried out by different authors to try to determine their influence on robot learning. To this end, walking, reaching, grasping and vocalization have been identified as the four most representative tasks addressed in the field, clustering the work of the different authors around them. The approach followed is multidisciplinary, discussing the relationships among DRs, embodied artificial intelligence and developmental psychology in humans in general, as well as for each of the tasks, and providing an overview of the many avenues of research that are still open in this field.},
  file = {/home/vaishnavahari/Zotero/storage/UFZUBL2X/Naya-Varela et al. - 2021 - Morphological Development in Robotic Learning A Survey.pdf}
}

@misc{pandeyAccessibleSurveyEvolutionary2022,
  title = {Accessible {{Survey}} of {{Evolutionary Robotics}} and {{Potential Future Research Directions}}},
  author = {Pandey, Hari Mohan},
  year = {2022},
  month = oct,
  number = {arXiv:2210.11704},
  eprint = {2210.11704},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.11704},
  urldate = {2025-05-23},
  abstract = {This paper reviews various Evolutionary Approaches applied to the domain of Evolutionary Robotics with the intention of resolving difficult problems in the areas of robotic design and control. Evolutionary Robotics is a fast-growing field that has attracted substantial research attention in recent years. The paper thus collates recent findings along with some anticipated applications. The reviewed literature is organized systematically to give a categorical overview of recent developments and is presented in tabulated form for quick reference. We discuss the outstanding potentialities and challenges that exist in robotics from an ER perspective, with the belief that these will be have the capacity to be addressed in the near future via the application of evolutionary approaches. The primary objective of this study is to explore the applicability of Evolutionary Approaches in robotic application development. We believe that this study will enable the researchers to utilize Evolutionary Approaches to solve complex outstanding problems in robotics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Robotics},
  file = {/home/vaishnavahari/Zotero/storage/L7JWSS8F/Pandey - 2022 - Accessible Survey of Evolutionary Robotics and Potential Future Research Directions.pdf;/home/vaishnavahari/Zotero/storage/TWUNHUBP/2210.html}
}

@misc{parakhAnyBodyBenchmarkSuite2025,
  title = {{{AnyBody}}: {{A Benchmark Suite}} for {{Cross-Embodiment Manipulation}}},
  shorttitle = {{{AnyBody}}},
  author = {Parakh, Meenal and Kirchmeyer, Alexandre and Han, Beining and Deng, Jia},
  year = {2025},
  month = may,
  number = {arXiv:2505.14986},
  eprint = {2505.14986},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.14986},
  urldate = {2025-06-11},
  abstract = {Generalizing control policies to novel embodiments remains a fundamental challenge in enabling scalable and transferable learning in robotics. While prior works have explored this in locomotion, a systematic study in the context of manipulation tasks remains limited, partly due to the lack of standardized benchmarks. In this paper, we introduce a benchmark for learning cross-embodiment manipulation, focusing on two foundational tasks-reach and push-across a diverse range of morphologies. The benchmark is designed to test generalization along three axes: interpolation (testing performance within a robot category that shares the same link structure), extrapolation (testing on a robot with a different link structure), and composition (testing on combinations of link structures). On the benchmark, we evaluate the ability of different RL policies to learn from multiple morphologies and to generalize to novel ones. Our study aims to answer whether morphology-aware training can outperform single-embodiment baselines, whether zero-shot generalization to unseen morphologies is feasible, and how consistently these patterns hold across different generalization regimes. The results highlight the current limitations of multi-embodiment learning and provide insights into how architectural and training design choices influence policy generalization.},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/7PYGKG67/Parakh et al. - 2025 - AnyBody A Benchmark Suite for Cross-Embodiment Manipulation.pdf;/home/vaishnavahari/Zotero/storage/XZUM75BY/2505.html}
}

@misc{pathakLearningControlSelfAssembling2019,
  title = {Learning to {{Control Self-Assembling Morphologies}}: {{A Study}} of {{Generalization}} via {{Modularity}}},
  shorttitle = {Learning to {{Control Self-Assembling Morphologies}}},
  author = {Pathak, Deepak and Lu, Chris and Darrell, Trevor and Isola, Phillip and Efros, Alexei A.},
  year = {2019},
  month = nov,
  number = {arXiv:1902.05546},
  eprint = {1902.05546},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.05546},
  urldate = {2025-06-11},
  abstract = {Contemporary sensorimotor learning approaches typically start with an existing complex agent (e.g., a robotic arm), which they learn to control. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to dynamically self-assemble into composite bodies while also learning to coordinate their behavior to control these bodies. Each primitive agent consists of a limb with a motor attached at one end. Limbs may choose to link up to form collectives. When a limb initiates a link-up action, and there is another limb nearby, the latter is magnetically connected to the 'parent' limb's motor. This forms a new single agent, which may further link with other agents. In this way, complex morphologies can emerge, controlled by a policy whose architecture is in explicit correspondence with the morphology. We evaluate the performance of these dynamic and modular agents in simulated environments. We demonstrate better generalization to test-time changes both in the environment, as well as in the structure of the agent, compared to static and monolithic baselines. Project video and code are available at https://pathak22.github.io/modular-assemblies/},
  archiveprefix = {arXiv},
  file = {/home/vaishnavahari/Zotero/storage/HBINIVDR/Pathak et al. - 2019 - Learning to Control Self-Assembling Morphologies A Study of Generalization via Modularity.pdf;/home/vaishnavahari/Zotero/storage/ZNUDC4RH/1902.html}
}

@article{whitmanLearningModularRobot2023,
  title = {Learning {{Modular Robot Control Policies}}},
  author = {Whitman, Julian and Travers, Matthew and Choset, Howie},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Robotics},
  volume = {39},
  number = {5},
  pages = {4095--4113},
  issn = {1941-0468},
  doi = {10.1109/TRO.2023.3284362},
  urldate = {2025-05-26},
  abstract = {Modular robots can be rearranged into a new design, perhaps each day, to handle a wide variety of tasks by forming a customized robot for each new task. However, reconfiguring just the mechanism is not sufficient: each design also requires its own unique control policy. One could craft a policy from scratch for each new design, but such an approach is not scalable, especially given the large number of designs that can be generated from even a small set of modules. Instead, we create a modular policy framework where the policy structure is conditioned on the hardware arrangement, and use just one training process to create a policy that controls a wide variety of designs. Our approach leverages the fact that the kinematics of a modular robot can be represented as a design graph, with nodes as modules and edges as connections between them. Given a robot, its design graph is used to create a policy graph with the same structure, where each node contains a deep neural network, and modules of the same type share knowledge via shared parameters (e.g., all legs on a hexapod share the same network parameters). We developed a model-based reinforcement learning algorithm, interleaving model learning and trajectory optimization to train the policy. We show the modular policy generalizes to a large number of designs that were not seen during training without any additional learning. Finally, we demonstrate the policy controlling a variety of designs to locomote with both simulated and real robots.},
  file = {/home/vaishnavahari/Zotero/storage/RVNXKBK9/Whitman et al. - 2023 - Learning Modular Robot Control Policies.pdf}
}
